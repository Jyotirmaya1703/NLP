{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a971d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9efd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Not all problems we might want to solve fall into this category. We may\n",
    "wish to generate new examples, or determine how likely some point is, or handle\n",
    "missing values and take advantage of a large set of unlabeled examples or examples\n",
    "from related tasks. A shortcoming of the current state of the art for industrial\n",
    "applications is that our learning algorithms require large amounts of supervised\n",
    "data to achieve good accuracy. In this part of the book, we discuss some of\n",
    "the speculative approaches to reducing the amount of labeled data necessary\n",
    "for existing models to work well and be applicable across a broader range of\n",
    "tasks. Accomplishing these goals usually requires some form of unsupervised or\n",
    "semi-supervised learning.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03cc3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'\\[[0-9]*\\]',' ',paragraph)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c0cab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c067ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "650ccca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae6c2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "352447e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " ',': 1,\n",
       " 'examples': 2,\n",
       " 'learning': 3,\n",
       " 'large': 4,\n",
       " 'data': 5,\n",
       " 'tasks': 6,\n",
       " 'set': 7,\n",
       " 'take': 8,\n",
       " 'advantage': 9,\n",
       " 'related': 10,\n",
       " 'unlabeled': 11,\n",
       " 'missing': 12,\n",
       " 'shortcoming': 13,\n",
       " 'current': 14,\n",
       " 'state': 15,\n",
       " 'art': 16,\n",
       " 'values': 17,\n",
       " 'point': 18,\n",
       " 'handle': 19,\n",
       " 'applications': 20,\n",
       " 'likely': 21,\n",
       " 'determine': 22,\n",
       " 'new': 23,\n",
       " 'generate': 24,\n",
       " 'wish': 25,\n",
       " 'may': 26,\n",
       " 'category': 27,\n",
       " 'fall': 28,\n",
       " 'solve': 29,\n",
       " 'want': 30,\n",
       " 'might': 31,\n",
       " 'industrial': 32,\n",
       " 'semi-supervised': 33,\n",
       " 'unsupervised': 34,\n",
       " 'necessary': 35,\n",
       " 'form': 36,\n",
       " 'requires': 37,\n",
       " 'usually': 38,\n",
       " 'goals': 39,\n",
       " 'accomplishing': 40,\n",
       " 'range': 41,\n",
       " 'broader': 42,\n",
       " 'across': 43,\n",
       " 'applicable': 44,\n",
       " 'well': 45,\n",
       " 'work': 46,\n",
       " 'models': 47,\n",
       " 'existing': 48,\n",
       " 'labeled': 49,\n",
       " 'algorithms': 50,\n",
       " 'amount': 51,\n",
       " 'reducing': 52,\n",
       " 'approaches': 53,\n",
       " 'speculative': 54,\n",
       " 'discuss': 55,\n",
       " 'book': 56,\n",
       " 'part': 57,\n",
       " 'accuracy': 58,\n",
       " 'good': 59,\n",
       " 'achieve': 60,\n",
       " 'supervised': 61,\n",
       " 'amounts': 62,\n",
       " 'require': 63,\n",
       " 'problems': 64}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9104b013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('existing', 0.23791289329528809),\n",
       " ('necessary', 0.22418862581253052),\n",
       " ('accomplishing', 0.18564918637275696),\n",
       " ('unsupervised', 0.17558209598064423),\n",
       " ('fall', 0.16295601427555084),\n",
       " ('achieve', 0.15489926934242249),\n",
       " ('reducing', 0.15221606194972992),\n",
       " ('learning', 0.14932912588119507),\n",
       " ('goals', 0.14522282779216766),\n",
       " ('supervised', 0.13638974726200104)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea618a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
